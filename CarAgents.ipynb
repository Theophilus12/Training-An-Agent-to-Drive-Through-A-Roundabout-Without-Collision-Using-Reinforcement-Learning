{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Theophilus12/Training-An-Agent-to-Drive-Through-A-Roundabout-Without-Collision-Using-Reinforcement-Learning/blob/main/CarAgents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89066c16",
      "metadata": {
        "id": "89066c16"
      },
      "outputs": [],
      "source": [
        "# !pip install stable-baselines"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23a46824",
      "metadata": {
        "id": "23a46824"
      },
      "source": [
        "## importing the necessary software libraries "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50ff1119",
      "metadata": {
        "id": "50ff1119"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import os\n",
        "import numpy as np\n",
        "import highway_env\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "#from stable_baselines import HER, SAC, PP02, DQN\n",
        "from stable_baselines3 import HerReplayBuffer, SAC, DDPG, TD3, PPO\n",
        "from stable_baselines3.common.noise import NormalActionNoise\n",
        "from stable_baselines3.common.evaluation import evaluate_policy \n",
        "from stable_baselines3.common.vec_env import DummyVecEnv"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8545a33",
      "metadata": {
        "id": "c8545a33"
      },
      "source": [
        "## Initializing & Testing the environment "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bd9bdbf",
      "metadata": {
        "id": "6bd9bdbf",
        "outputId": "bf988811-fc57-48d8-d7eb-43f0a886794b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        }
      ],
      "source": [
        "env_name = \"roundabout-v0\"\n",
        "env = gym.make(env_name)\n",
        "\n",
        "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
        "#model = PPO(\"MultiInputPolicy\", env, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5579de52",
      "metadata": {
        "id": "5579de52",
        "outputId": "1f94770d-5d1b-4558-c216-6658d6d604e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode:10 Score:9.68\n"
          ]
        }
      ],
      "source": [
        "# testing the environment \n",
        "episodes = 10\n",
        "for episode in range(1, episodes+1):\n",
        "    done = False\n",
        "    score = 0\n",
        "    #reset() function reset the environment to its initial stateThis approach restores the environment to its original condition and allows the agent to observe it.\n",
        "    state = env.reset()\n",
        "while not done:\n",
        "#we can visually inspect the environmnet anytime by calling the render() function \n",
        "        env.render()\n",
        "        action = env.action_space.sample()\n",
        "        next_state, reward, done, info = env.step(action)\n",
        "        score+=reward\n",
        "print('Episode:{} Score:{}'.format(episode, score))\n",
        "#print(info) \n",
        "#print(done)\n",
        "#It completes the process and shuts down the environment, clearing up the resources inextricably linked with it.              \n",
        "env.close()  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f993556",
      "metadata": {
        "id": "9f993556"
      },
      "source": [
        "lets evaluate the untrained agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8152c575",
      "metadata": {
        "scrolled": false,
        "id": "8152c575",
        "outputId": "8d0343f5-9177-405e-a681-d73057363f39"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Anaconda\\envs\\agent\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:69: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean_reward:9.06) +/- 0.10\n"
          ]
        }
      ],
      "source": [
        "#lets evaluate the untrained agent\n",
        "eval_env = gym.make(\"roundabout-v0\")\n",
        "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes= 10)\n",
        "print(f\"mean_reward:{mean_reward:.2f}) +/- {std_reward:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5a0f734",
      "metadata": {
        "id": "b5a0f734"
      },
      "source": [
        "## Understanding the environment "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea4f8dc7",
      "metadata": {
        "id": "ea4f8dc7"
      },
      "source": [
        "There are two major spaces in an environment, ACTION SPACE(actions that the agent can take within the environment) and OBSERVATION SPACE(is it continuous or discrete, the range of values of each element in the observation, the python datatype of each element in the observation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97ef7810",
      "metadata": {
        "id": "97ef7810",
        "outputId": "c3e35986-d337-4046-bf3e-1a7a67e00cd5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Discrete(5)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env.action_space #we have 5 types of action that our agent can perform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be8013f5",
      "metadata": {
        "id": "be8013f5",
        "outputId": "37899f11-7317-4983-9888-cf6b50f42214"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env.action_space.sample() \n",
        "# generating random actions, that our agent can perform"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04958fc0",
      "metadata": {
        "id": "04958fc0"
      },
      "source": [
        "understaing the observation space nature\n",
        "-> Box: gym data type describing numpy arrays with elements taking values continuously  in a range, \n",
        "(5,5)-> means that it is 5 by 5 dimensional vector NumPy array\n",
        "range of element-> lower range[-inf] and upper range [+ inf] means the elements cantake values between -infinity and + infinity\n",
        "datatype -> np.float32 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e68f6a5e",
      "metadata": {
        "id": "e68f6a5e",
        "outputId": "1f865b8e-0641-4a0d-ef3d-42506f796eca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Box([[-inf -inf -inf -inf -inf]\n",
              " [-inf -inf -inf -inf -inf]\n",
              " [-inf -inf -inf -inf -inf]\n",
              " [-inf -inf -inf -inf -inf]\n",
              " [-inf -inf -inf -inf -inf]], [[inf inf inf inf inf]\n",
              " [inf inf inf inf inf]\n",
              " [inf inf inf inf inf]\n",
              " [inf inf inf inf inf]\n",
              " [inf inf inf inf inf]], (5, 5), float32)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env.observation_space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ad83423",
      "metadata": {
        "id": "4ad83423",
        "outputId": "80d2d676-8e1b-4912-861f-5ea09b46605d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 1.8947269 ,  0.26578045,  0.25293696, -0.24473181,  0.15543427],\n",
              "       [ 0.12222444, -0.65149516, -0.68574   ,  0.2085767 ,  0.2860846 ],\n",
              "       [-0.20846123, -0.63872725,  0.8249831 ,  0.3121078 , -0.06785931],\n",
              "       [-0.1622476 ,  0.73136103, -2.407764  ,  2.1723502 ,  0.13067444],\n",
              "       [ 0.24733485,  2.5595767 , -0.3607785 ,  0.00546531, -0.80610687]],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env.observation_space.sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e1efd31",
      "metadata": {
        "scrolled": false,
        "id": "3e1efd31",
        "outputId": "42c76078-66dc-496e-cf05-51cdcd895fcb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 1.0000000e+00,  2.0000000e-02,  4.4999999e-01,  0.0000000e+00,\n",
              "        -5.3333336e-01],\n",
              "       [ 1.0000000e+00, -5.4256640e-02,  1.9249992e-01,  9.4529361e-01,\n",
              "         2.6643366e-01],\n",
              "       [ 1.0000000e+00, -2.1317315e-01,  1.1025972e-01,  6.0933304e-01,\n",
              "         1.0000000e+00],\n",
              "       [ 1.0000000e+00,  1.0000000e+00, -2.0000000e-02, -9.3942398e-01,\n",
              "         2.2204460e-16],\n",
              "       [ 1.0000000e+00, -1.6246326e-01, -1.1664343e-01, -8.1259990e-01,\n",
              "         1.0000000e+00]], dtype=float32)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#This approach reset the environment to its initial state and start the simulation of the environment \n",
        "initial_state = env.reset()\n",
        "initial_state"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf21d8ea",
      "metadata": {
        "id": "cf21d8ea"
      },
      "source": [
        "NOTE: the render() function only works if reset() was called before, Otherwise it wont display the result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2f6db26",
      "metadata": {
        "id": "e2f6db26",
        "outputId": "62cdd9dc-e6e6-4d10-94d4-62ee53f45aed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'action': {'type': 'DiscreteMetaAction'},\n",
            " 'centering_position': [0.3, 0.5],\n",
            " 'collision_reward': -1,\n",
            " 'controlled_vehicles': 1,\n",
            " 'duration': 40,\n",
            " 'ego_spacing': 2,\n",
            " 'high_speed_reward': 0.4,\n",
            " 'initial_lane_id': None,\n",
            " 'lane_change_reward': 0,\n",
            " 'lanes_count': 4,\n",
            " 'manual_control': False,\n",
            " 'observation': {'type': 'Kinematics'},\n",
            " 'offroad_terminal': False,\n",
            " 'offscreen_rendering': False,\n",
            " 'other_vehicles_type': 'highway_env.vehicle.behavior.IDMVehicle',\n",
            " 'policy_frequency': 1,\n",
            " 'real_time_rendering': False,\n",
            " 'render_agent': True,\n",
            " 'reward_speed_range': [20, 30],\n",
            " 'right_lane_reward': 0.1,\n",
            " 'scaling': 5.5,\n",
            " 'screen_height': 150,\n",
            " 'screen_width': 600,\n",
            " 'show_trajectories': False,\n",
            " 'simulation_frequency': 15,\n",
            " 'vehicles_count': 50,\n",
            " 'vehicles_density': 1}\n"
          ]
        }
      ],
      "source": [
        "import pprint\n",
        "\n",
        "env = gym.make(\"highway-v0\")\n",
        "pprint.pprint(env.config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b60eda6",
      "metadata": {
        "id": "1b60eda6",
        "outputId": "f97cd40d-eb22-4f09-ab8f-fae93a9c759c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Congrats! You just generated your first trajectory:\n",
            "[[array([[ 1.0000000e+00,  2.0000000e-02,  4.4999999e-01,  0.0000000e+00,\n",
            "        -5.3333336e-01],\n",
            "       [ 1.0000000e+00, -2.6471149e-02,  1.9824046e-01,  9.6462458e-01,\n",
            "         1.2880681e-01],\n",
            "       [ 1.0000000e+00, -2.2279723e-01,  8.9226656e-02,  3.9587957e-01,\n",
            "         9.8850363e-01],\n",
            "       [ 1.0000000e+00,  1.0000000e+00, -2.0000000e-02, -8.8721341e-01,\n",
            "         2.2204460e-16],\n",
            "       [ 1.0000000e+00, -1.7194796e-01, -1.0214646e-01, -5.6082666e-01,\n",
            "         9.4406599e-01]], dtype=float32), 2, 0.8800000000000001, False, array([[ 1.0000000e+00,  2.4060752e-02,  3.7019700e-01,  4.8730187e-02,\n",
            "        -5.3110248e-01],\n",
            "       [ 1.0000000e+00, -1.2613325e-01,  2.1319439e-01,  8.3840197e-01,\n",
            "         6.5646183e-01],\n",
            "       [ 1.0000000e+00,  1.1435085e-01,  1.7231613e-01,  8.8105738e-01,\n",
            "        -4.1331553e-01],\n",
            "       [ 1.0000000e+00, -2.0239449e-01,  5.5715024e-02,  1.2514360e-01,\n",
            "         1.0000000e+00],\n",
            "       [ 1.0000000e+00,  1.0000000e+00, -2.0000000e-02, -8.8721341e-01,\n",
            "         2.2204460e-16]], dtype=float32)]]\n"
          ]
        }
      ],
      "source": [
        "env = gym.make(\"roundabout-v0\")\n",
        "state = env.reset()\n",
        "trajectory = []\n",
        "for _ in range(1):\n",
        "    action = env.action_space.sample()\n",
        "    next_state, reward, done, info = env.step(action)\n",
        "    trajectory.append([state, action, reward, done, next_state])\n",
        "    state = next_state\n",
        "env.close()\n",
        "\n",
        "print(f\"Congrats! You just generated your first trajectory:\\n{trajectory}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b20f3905",
      "metadata": {
        "id": "b20f3905"
      },
      "source": [
        "## Training the RL model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7884fbb",
      "metadata": {
        "id": "b7884fbb"
      },
      "outputs": [],
      "source": [
        "#creating our Log Directory\n",
        "log_path =os.path.join('Training', 'Logs')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a75781d",
      "metadata": {
        "id": "9a75781d"
      },
      "outputs": [],
      "source": [
        "log_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b09cdce0",
      "metadata": {
        "scrolled": true,
        "id": "b09cdce0"
      },
      "outputs": [],
      "source": [
        "#creating a model\n",
        "model = PPO('MlpPolicy', env, verbose=1)\n",
        "model.learn(total_timesteps=20000)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfdfabe8",
      "metadata": {
        "id": "bfdfabe8"
      },
      "source": [
        "## Save and Reload Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "06db717a",
      "metadata": {
        "id": "06db717a"
      },
      "outputs": [],
      "source": [
        "#PP0_path = os.path.join('Traning', 'Saved Models', 'PPO_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5128f7e4",
      "metadata": {
        "id": "5128f7e4"
      },
      "outputs": [],
      "source": [
        "os.path.join(os.path.sep, 'Traning', 'Saved Models', 'PPO_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1717ecdd",
      "metadata": {
        "scrolled": true,
        "id": "1717ecdd"
      },
      "outputs": [],
      "source": [
        "model.save('roundabout')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6c9a6be",
      "metadata": {
        "id": "d6c9a6be"
      },
      "outputs": [],
      "source": [
        "del model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2dfa96e3",
      "metadata": {
        "scrolled": true,
        "id": "2dfa96e3"
      },
      "outputs": [],
      "source": [
        "model= PPO.load('roundabout')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "151b6974",
      "metadata": {
        "id": "151b6974"
      },
      "outputs": [],
      "source": [
        "#log_dir = \"/tmp/gym/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d6d148e",
      "metadata": {
        "id": "4d6d148e"
      },
      "outputs": [],
      "source": [
        "#os.makedirs(log_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "155bd368",
      "metadata": {
        "id": "155bd368"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5a699c8",
      "metadata": {
        "id": "e5a699c8"
      },
      "outputs": [],
      "source": [
        "#mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10, render=True)\n",
        "evaluate_policy(model, env, n_eval_episodes=10, render=True)\n",
        "#print(f\"mean_reward:{mean_reward:.2f}) +/- {std_reward:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f77c92b",
      "metadata": {
        "id": "7f77c92b"
      },
      "outputs": [],
      "source": [
        "env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39868ea8",
      "metadata": {
        "id": "39868ea8"
      },
      "source": [
        "## Testing the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1efabfd1",
      "metadata": {
        "id": "1efabfd1"
      },
      "outputs": [],
      "source": [
        "obs = env.reset()\n",
        "while True:\n",
        "    action, _states = model.predict(obs)\n",
        "    obs, rewards, done, info = env.step(action)\n",
        "    env.render()\n",
        "    if done: \n",
        "        print('info', info)\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e52eedb4",
      "metadata": {
        "id": "e52eedb4"
      },
      "outputs": [],
      "source": [
        "env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ae987c9",
      "metadata": {
        "id": "9ae987c9"
      },
      "source": [
        "## Using an Alternate Algorithm to test the agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ed8b172",
      "metadata": {
        "id": "7ed8b172"
      },
      "outputs": [],
      "source": [
        "from stable_baselines3 import DQN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d99092a",
      "metadata": {
        "id": "5d99092a"
      },
      "outputs": [],
      "source": [
        "model = DQN('MlpPolicy', env, verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a90610f",
      "metadata": {
        "id": "7a90610f"
      },
      "outputs": [],
      "source": [
        "model.learn(total_timesteps=20000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3278982",
      "metadata": {
        "id": "e3278982"
      },
      "outputs": [],
      "source": [
        "dqn_path = os.path.join('Training', 'Saved Models', 'DQN_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3cf00de",
      "metadata": {
        "id": "e3cf00de"
      },
      "outputs": [],
      "source": [
        "model.save(dqn_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1e7b0c0",
      "metadata": {
        "id": "e1e7b0c0"
      },
      "outputs": [],
      "source": [
        "model = DQN.load(dqn_path, env=env)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fba4671",
      "metadata": {
        "id": "2fba4671"
      },
      "outputs": [],
      "source": [
        "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff80a215",
      "metadata": {
        "id": "ff80a215"
      },
      "outputs": [],
      "source": [
        "env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "fdb470f2",
      "metadata": {
        "id": "fdb470f2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}